# Высокопроизводительные вычисления
## Бехтерев Алексей, группа 6133
____
# Лабораторная работа 0 (MatMul)
Лабораторная работа выполнена на языке Python. Использование CUDA достигается библиотекой Numba.
Выполнение операции (метода) по произведению матриц в параллельном режиме обеспечивает декоратор **@cuda.jit**, который производит вычисления на CUDA

В результате получается достичь значительного ускорения вычислений при использовании GPU в сравнении с использованием CPU.

Эксперименты с варьированием размерности матриц представлены в файле result.csv
____
# Лабораторная работа 1 (VectorSum)
Лабораторная работа была выполнена на языке Python, в блокноте Google Colab. Использование CUDA достигается библиотекой Numba, а именно декоратором **@cuda.jit**, как и в прошлой ЛР.

Параллельность достигается в сложении несколькими нитями элементов вектора, а именно в строчке **sum += buffer[i]**

Также в файле result1.csv представлены результаты экспериментальных запусков на различных размерностях вектора, время вычисления суммы на CPU/GPU и ускорение.
Из этих данных видно, что с увелечением размерности увеличивается время вычислений на CPU, однако на GPU остается примерно одинаковым, в результате чего растет ускорение.
____
# Лабораторная работа 3 (Image bilinear interpolation)
Лабораторная работа была выполнена на языке Python, в блокноте Google Colab. Использование CUDA достигается библиотекой Numba, а именно декоратором **@cuda.jit**, как и в прошлых ЛР.

Параллельность достигается в вычислении пикселов разными нитями.
____
# Лабораторная работа 4 (Bilateral filtering)
Лабораторная работа была выполнена на языке Python, в блокноте Google Colab. Использование CUDA достигается библиотекой Numba, а именно декоратором **@cuda.jit**, как и в прошлых ЛР.

Параллельность достигается в вычислении пикселов разными нитями.

В последней секции блокнота представлны результаты экспериментов с варьированием параметров размытия. Из них следует, что при больших параметрах растет ускорение CPU/GPU.
