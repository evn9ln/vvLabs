{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jDQVhkr02Ut4"
      },
      "outputs": [],
      "source": [
        "from numba import cuda, int32\n",
        "import numba\n",
        "import time\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threads_per_block = 32"
      ],
      "metadata": {
        "id": "D0SfKTAT7ckv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Cdj_NDT22W33"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def GPU_sum(vector, result):\n",
        "    buffer = cuda.shared.array(threads_per_block, dtype=int32)\n",
        "\n",
        "    idx = cuda.threadIdx.x + cuda.blockIdx.x * threads_per_block\n",
        "\n",
        "    buffer[cuda.threadIdx.x] = 0\n",
        "\n",
        "    if idx < vector.shape[0]:\n",
        "        buffer[cuda.threadIdx.x] = vector[idx]\n",
        "\n",
        "        cuda.syncthreads()\n",
        "        if cuda.threadIdx.x == 0:\n",
        "            sum = 0\n",
        "            for i in range(threads_per_block):\n",
        "                sum += buffer[i]\n",
        "            cuda.atomic.add(result, 0, sum)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "PBJGqpt92Zvt"
      },
      "outputs": [],
      "source": [
        "def CPU_sum(vector):\n",
        "    return np.sum(vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "2dRcI26U2cgc"
      },
      "outputs": [],
      "source": [
        "def perform_vector_sum(vector_size):\n",
        "    vector = np.random.randint(-10, 10, vector_size)\n",
        "    result = np.zeros(1, dtype=np.int32)\n",
        "\n",
        "    # print(\"Input vector: \", vector)\n",
        "\n",
        "    print(\"CPU calculation:\")\n",
        "\n",
        "    start_time_CPU = time.time()\n",
        "    CPU_result = CPU_sum(vector)\n",
        "    result_time_CPU = time.time() - start_time_CPU\n",
        "\n",
        "    # print(\"Result CPU : \", CPU_result)\n",
        "    print(\"Time CPU: \", result_time_CPU)\n",
        "\n",
        "    print(\"_________________________________________________________\")\n",
        "\n",
        "    print(\"GPU calculation: \")\n",
        "\n",
        "    GPU_vector = cuda.to_device(vector)\n",
        "    GPU_for_res = cuda.to_device(result)\n",
        "\n",
        "    start_time_GPU = time.time()\n",
        "    GPU_sum[threads_per_block, threads_per_block](GPU_vector, GPU_for_res)\n",
        "    result_time_GPU = time.time() - start_time_GPU\n",
        "\n",
        "    result_GPU = GPU_for_res.copy_to_host()\n",
        "\n",
        "    # print(\"Result GPU : \", result_GPU)\n",
        "    print(\"Time GPU: \", result_time_GPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbKOjdHs2fsC",
        "outputId": "82138e69-31c4-40b7-e00f-67709610698d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU calculation:\n",
            "Time CPU:  0.0009224414825439453\n",
            "_________________________________________________________\n",
            "GPU calculation: \n",
            "Time GPU:  0.00019788742065429688\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    vector_size = 100000\n",
        "    perform_vector_sum(vector_size)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}